#!/usr/bin/env python3
"""
å®æ—¶æ€§èƒ½ç›‘æ§è„šæœ¬
ç›‘æ§LLM-VTuberç³»ç»Ÿçš„å„é¡¹æ€§èƒ½æŒ‡æ ‡
"""
import asyncio
import time
import psutil
import json
import websockets
from datetime import datetime
from typing import Dict, Any, List
from loguru import logger

class RealTimePerformanceMonitor:
    def __init__(self):
        self.metrics_history = []
        self.performance_thresholds = {
            "llm_response_time": 5.0,    # LLMå“åº”æ—¶é—´é˜ˆå€¼(ç§’)
            "tts_generation_time": 3.0,  # TTSç”Ÿæˆæ—¶é—´é˜ˆå€¼(ç§’)
            "asr_processing_time": 2.0,   # ASRå¤„ç†æ—¶é—´é˜ˆå€¼(ç§’)
            "cpu_usage": 80.0,           # CPUä½¿ç”¨ç‡é˜ˆå€¼(%)
            "memory_usage": 85.0,         # å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼(%)
            "disk_usage": 90.0           # ç£ç›˜ä½¿ç”¨ç‡é˜ˆå€¼(%)
        }
        
    def get_system_metrics(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        return {
            "timestamp": datetime.now().isoformat(),
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_percent": psutil.disk_usage('/').percent,
            "network_io": psutil.net_io_counters()._asdict(),
            "process_count": len(psutil.pids())
        }
    
    def check_performance_alerts(self, metrics: Dict[str, Any]) -> List[str]:
        """æ£€æŸ¥æ€§èƒ½å‘Šè­¦"""
        alerts = []
        
        if metrics["cpu_percent"] > self.performance_thresholds["cpu_usage"]:
            alerts.append(f"âš ï¸  CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics['cpu_percent']:.1f}%")
        
        if metrics["memory_percent"] > self.performance_thresholds["memory_usage"]:
            alerts.append(f"âš ï¸  å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics['memory_percent']:.1f}%")
        
        if metrics["disk_percent"] > self.performance_thresholds["disk_usage"]:
            alerts.append(f"âš ï¸  ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics['disk_percent']:.1f}%")
        
        return alerts
    
    async def test_llm_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•LLMæ€§èƒ½"""
        logger.info("ğŸ§  æµ‹è¯•LLMæ€§èƒ½...")
        
        try:
            uri = 'ws://localhost:12393/client-ws'
            async with websockets.connect(uri) as websocket:
                # ç­‰å¾…è¿æ¥å»ºç«‹
                await asyncio.sleep(1)
                
                # å‘é€æµ‹è¯•æ¶ˆæ¯
                test_message = {
                    'type': 'text-input',
                    'content': 'Hello! How are you?'
                }
                
                start_time = time.time()
                await websocket.send(json.dumps(test_message))
                
                # ç›‘å¬å“åº”
                response_times = []
                llm_start = None
                tts_start = None
                
                timeout = 30
                while time.time() - start_time < timeout:
                    try:
                        response = await asyncio.wait_for(websocket.recv(), timeout=5.0)
                        data = json.loads(response)
                        current_time = time.time()
                        
                        if data.get('type') == 'full-text' and llm_start is None:
                            llm_start = current_time
                            logger.info(f"ğŸ“ LLMå¼€å§‹å“åº”: {current_time - start_time:.2f}s")
                        
                        elif data.get('type') == 'audio' and tts_start is None:
                            tts_start = current_time
                            logger.info(f"ğŸ”Š TTSå¼€å§‹åˆæˆ: {current_time - start_time:.2f}s")
                        
                        elif data.get('type') == 'control' and data.get('text') == 'conversation-chain-end':
                            total_time = current_time - start_time
                            logger.info(f"âœ… å¯¹è¯å®Œæˆ: {total_time:.2f}s")
                            break
                            
                    except asyncio.TimeoutError:
                        break
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                llm_response_time = (llm_start - start_time) if llm_start else None
                tts_generation_time = (tts_start - llm_start) if tts_start and llm_start else None
                total_response_time = time.time() - start_time
                
                return {
                    "llm_response_time": llm_response_time,
                    "tts_generation_time": tts_generation_time,
                    "total_response_time": total_response_time,
                    "success": llm_start is not None
                }
                
        except Exception as e:
            logger.error(f"âŒ LLMæ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def analyze_performance_trends(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        if len(self.metrics_history) < 2:
            return {"trend": "insufficient_data"}
        
        recent_metrics = self.metrics_history[-5:]  # æœ€è¿‘5æ¬¡è®°å½•
        
        # è®¡ç®—è¶‹åŠ¿
        cpu_trend = self._calculate_trend([m["cpu_percent"] for m in recent_metrics])
        memory_trend = self._calculate_trend([m["memory_percent"] for m in recent_metrics])
        
        return {
            "cpu_trend": cpu_trend,
            "memory_trend": memory_trend,
            "sample_count": len(recent_metrics)
        }
    
    def _calculate_trend(self, values: List[float]) -> str:
        """è®¡ç®—è¶‹åŠ¿æ–¹å‘"""
        if len(values) < 2:
            return "stable"
        
        first_half = values[:len(values)//2]
        second_half = values[len(values)//2:]
        
        first_avg = sum(first_half) / len(first_half)
        second_avg = sum(second_half) / len(second_half)
        
        if second_avg > first_avg * 1.1:
            return "increasing"
        elif second_avg < first_avg * 0.9:
            return "decreasing"
        else:
            return "stable"
    
    def generate_performance_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if not self.metrics_history:
            return {"error": "no_data"}
        
        latest_metrics = self.metrics_history[-1]
        trends = self.analyze_performance_trends()
        alerts = self.check_performance_alerts(latest_metrics)
        
        # æ€§èƒ½è¯„åˆ†
        performance_score = self._calculate_performance_score(latest_metrics)
        
        return {
            "timestamp": latest_metrics["timestamp"],
            "current_metrics": latest_metrics,
            "performance_score": performance_score,
            "trends": trends,
            "alerts": alerts,
            "recommendations": self._generate_recommendations(latest_metrics, trends)
        }
    
    def _calculate_performance_score(self, metrics: Dict[str, Any]) -> int:
        """è®¡ç®—æ€§èƒ½è¯„åˆ† (0-100)"""
        score = 100
        
        # CPUä½¿ç”¨ç‡è¯„åˆ†
        if metrics["cpu_percent"] > 80:
            score -= 20
        elif metrics["cpu_percent"] > 60:
            score -= 10
        
        # å†…å­˜ä½¿ç”¨ç‡è¯„åˆ†
        if metrics["memory_percent"] > 85:
            score -= 20
        elif metrics["memory_percent"] > 70:
            score -= 10
        
        # ç£ç›˜ä½¿ç”¨ç‡è¯„åˆ†
        if metrics["disk_percent"] > 90:
            score -= 15
        elif metrics["disk_percent"] > 80:
            score -= 5
        
        return max(0, score)
    
    def _generate_recommendations(self, metrics: Dict[str, Any], trends: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if metrics["cpu_percent"] > 70:
            recommendations.append("ğŸ’¡ è€ƒè™‘ä¼˜åŒ–CPUå¯†é›†å‹ä»»åŠ¡æˆ–å¢åŠ å¤„ç†æ ¸å¿ƒ")
        
        if metrics["memory_percent"] > 75:
            recommendations.append("ğŸ’¡ è€ƒè™‘å¢åŠ å†…å­˜æˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨")
        
        if metrics["disk_percent"] > 85:
            recommendations.append("ğŸ’¡ æ¸…ç†ç£ç›˜ç©ºé—´æˆ–å¢åŠ å­˜å‚¨å®¹é‡")
        
        if trends.get("cpu_trend") == "increasing":
            recommendations.append("ğŸ’¡ CPUä½¿ç”¨ç‡å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œå»ºè®®ç›‘æ§ç³»ç»Ÿè´Ÿè½½")
        
        if trends.get("memory_trend") == "increasing":
            recommendations.append("ğŸ’¡ å†…å­˜ä½¿ç”¨ç‡å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼")
        
        return recommendations
    
    async def monitor_loop(self, interval: int = 30):
        """ç›‘æ§å¾ªç¯"""
        logger.info("ğŸ“Š å¼€å§‹å®æ—¶æ€§èƒ½ç›‘æ§...")
        logger.info(f"ç›‘æ§é—´éš”: {interval}ç§’")
        
        while True:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                system_metrics = self.get_system_metrics()
                self.metrics_history.append(system_metrics)
                
                # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
                if len(self.metrics_history) > 100:
                    self.metrics_history = self.metrics_history[-50:]
                
                # æ£€æŸ¥å‘Šè­¦
                alerts = self.check_performance_alerts(system_metrics)
                if alerts:
                    for alert in alerts:
                        logger.warning(alert)
                
                # æ¯5åˆ†é’Ÿè¿›è¡Œä¸€æ¬¡LLMæ€§èƒ½æµ‹è¯•
                if len(self.metrics_history) % 10 == 0:
                    llm_performance = await self.test_llm_performance()
                    if llm_performance.get("success"):
                        logger.info(f"ğŸ§  LLMå“åº”æ—¶é—´: {llm_performance.get('llm_response_time', 'N/A'):.2f}s")
                        logger.info(f"ğŸ”Š TTSç”Ÿæˆæ—¶é—´: {llm_performance.get('tts_generation_time', 'N/A'):.2f}s")
                
                # æ¯10åˆ†é’Ÿç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
                if len(self.metrics_history) % 20 == 0:
                    report = self.generate_performance_report()
                    logger.info(f"ğŸ“Š æ€§èƒ½è¯„åˆ†: {report.get('performance_score', 'N/A')}/100")
                    
                    # ä¿å­˜æŠ¥å‘Š
                    report_file = f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    with open(report_file, 'w', encoding='utf-8') as f:
                        json.dump(report, f, ensure_ascii=False, indent=2)
                    logger.info(f"ğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
                
                # æ˜¾ç¤ºå½“å‰çŠ¶æ€
                logger.info(f"ğŸ’» CPU: {system_metrics['cpu_percent']:.1f}% | "
                          f"å†…å­˜: {system_metrics['memory_percent']:.1f}% | "
                          f"ç£ç›˜: {system_metrics['disk_percent']:.1f}%")
                
                await asyncio.sleep(interval)
                
            except KeyboardInterrupt:
                logger.info("ğŸ›‘ ç›‘æ§å·²åœæ­¢")
                break
            except Exception as e:
                logger.error(f"âŒ ç›‘æ§é”™è¯¯: {e}")
                await asyncio.sleep(interval)

async def main():
    monitor = RealTimePerformanceMonitor()
    
    print("ğŸš€ LLM-VTuberæ€§èƒ½ç›‘æ§å™¨")
    print("=" * 50)
    print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
    print("=" * 50)
    
    await monitor.monitor_loop(interval=30)

if __name__ == "__main__":
    asyncio.run(main())
