#!/usr/bin/env python3
"""
2-3ç§’å“åº”æ—¶é—´æµ‹è¯•è„šæœ¬
ä¸“é—¨æµ‹è¯•å’ŒéªŒè¯2-3ç§’å“åº”æ—¶é—´ç›®æ ‡
"""
import asyncio
import time
import json
import websockets
import statistics
from typing import List, Dict, Any
from loguru import logger

class ResponseTimeTester:
    def __init__(self):
        self.test_results = []
        self.target_time = 3.0  # ç›®æ ‡å“åº”æ—¶é—´3ç§’
        self.success_threshold = 0.8  # 80%æˆåŠŸç‡
        
    async def test_single_response(self, test_input: str) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªå“åº”"""
        logger.info(f"ğŸ§ª æµ‹è¯•è¾“å…¥: '{test_input}'")
        
        start_time = time.time()
        
        try:
            uri = 'ws://localhost:12393/client-ws'
            async with websockets.connect(uri) as websocket:
                # ç­‰å¾…è¿æ¥å»ºç«‹
                await asyncio.sleep(0.5)
                
                # å‘é€æµ‹è¯•æ¶ˆæ¯
                test_message = {
                    'type': 'text-input',
                    'content': test_input
                }
                
                await websocket.send(json.dumps(test_message))
                
                # è®°å½•å…³é”®æ—¶é—´ç‚¹
                llm_start = None
                llm_end = None
                tts_start = None
                tts_end = None
                total_end = None
                
                # ç›‘å¬å“åº”
                timeout = 10  # 10ç§’æ€»è¶…æ—¶
                while time.time() - start_time < timeout:
                    try:
                        response = await asyncio.wait_for(websocket.recv(), timeout=2.0)
                        data = json.loads(response)
                        current_time = time.time()
                        
                        # è®°å½•LLMå¼€å§‹å“åº”
                        if data.get('type') == 'full-text' and llm_start is None:
                            llm_start = current_time
                            llm_response_time = llm_start - start_time
                            logger.info(f"ğŸ“ LLMå¼€å§‹å“åº”: {llm_response_time:.2f}s")
                        
                        # è®°å½•TTSå¼€å§‹åˆæˆ
                        elif data.get('type') == 'audio' and tts_start is None:
                            tts_start = current_time
                            tts_response_time = tts_start - start_time
                            logger.info(f"ğŸ”Š TTSå¼€å§‹åˆæˆ: {tts_response_time:.2f}s")
                        
                        # è®°å½•å¯¹è¯ç»“æŸ
                        elif data.get('type') == 'control' and data.get('text') == 'conversation-chain-end':
                            total_end = current_time
                            total_time = total_end - start_time
                            logger.info(f"âœ… å¯¹è¯å®Œæˆ: {total_time:.2f}s")
                            break
                            
                    except asyncio.TimeoutError:
                        logger.warning("å“åº”è¶…æ—¶")
                        break
                
                # è®¡ç®—æ—¶é—´æŒ‡æ ‡
                total_time = time.time() - start_time
                llm_time = (llm_start - start_time) if llm_start else None
                tts_time = (tts_start - llm_start) if tts_start and llm_start else None
                
                result = {
                    "test_input": test_input,
                    "total_time": total_time,
                    "llm_response_time": llm_time,
                    "tts_generation_time": tts_time,
                    "success": total_time <= self.target_time,
                    "timestamp": time.time()
                }
                
                # è¯„ä¼°ç»“æœ
                if result["success"]:
                    logger.info(f"âœ… æµ‹è¯•æˆåŠŸ: {total_time:.2f}s <= {self.target_time}s")
                else:
                    logger.warning(f"âŒ æµ‹è¯•å¤±è´¥: {total_time:.2f}s > {self.target_time}s")
                
                return result
                
        except Exception as e:
            logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
            return {
                "test_input": test_input,
                "error": str(e),
                "success": False,
                "total_time": None
            }
    
    async def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹2-3ç§’å“åº”æ—¶é—´ç»¼åˆæµ‹è¯•...")
        logger.info("=" * 60)
        
        # æµ‹è¯•ç”¨ä¾‹
        test_cases = [
            "Hello!",
            "How are you?",
            "What's your name?",
            "Tell me a joke.",
            "What's the weather like?",
            "How old are you?",
            "What do you like to do?",
            "Do you have any hobbies?",
            "What's your favorite color?",
            "Can you help me?"
        ]
        
        # è¿è¡Œæµ‹è¯•
        for i, test_input in enumerate(test_cases, 1):
            logger.info(f"ğŸ“‹ æµ‹è¯• {i}/{len(test_cases)}")
            result = await self.test_single_response(test_input)
            self.test_results.append(result)
            
            # æµ‹è¯•é—´éš”
            await asyncio.sleep(1)
        
        # åˆ†æç»“æœ
        return self.analyze_test_results()
    
    def analyze_test_results(self) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not self.test_results:
            return {"error": "no_test_results"}
        
        # åŸºæœ¬ç»Ÿè®¡
        successful_tests = [r for r in self.test_results if r.get("success", False)]
        failed_tests = [r for r in self.test_results if not r.get("success", False)]
        
        success_rate = len(successful_tests) / len(self.test_results)
        
        # æ—¶é—´ç»Ÿè®¡
        total_times = [r["total_time"] for r in self.test_results if r.get("total_time")]
        llm_times = [r["llm_response_time"] for r in self.test_results if r.get("llm_response_time")]
        tts_times = [r["tts_generation_time"] for r in self.test_results if r.get("tts_generation_time")]
        
        analysis = {
            "test_summary": {
                "total_tests": len(self.test_results),
                "successful_tests": len(successful_tests),
                "failed_tests": len(failed_tests),
                "success_rate": success_rate,
                "target_achieved": success_rate >= self.success_threshold
            },
            "response_times": {
                "average_total_time": statistics.mean(total_times) if total_times else None,
                "median_total_time": statistics.median(total_times) if total_times else None,
                "min_total_time": min(total_times) if total_times else None,
                "max_total_time": max(total_times) if total_times else None,
                "average_llm_time": statistics.mean(llm_times) if llm_times else None,
                "average_tts_time": statistics.mean(tts_times) if tts_times else None
            },
            "performance_grade": self._calculate_performance_grade(success_rate),
            "recommendations": self._generate_recommendations(success_rate, total_times),
            "detailed_results": self.test_results
        }
        
        return analysis
    
    def _calculate_performance_grade(self, success_rate: float) -> str:
        """è®¡ç®—æ€§èƒ½ç­‰çº§"""
        if success_rate >= 0.9:
            return "A+ (ä¼˜ç§€)"
        elif success_rate >= 0.8:
            return "A (è‰¯å¥½)"
        elif success_rate >= 0.7:
            return "B (ä¸€èˆ¬)"
        elif success_rate >= 0.6:
            return "C (éœ€è¦æ”¹è¿›)"
        else:
            return "D (éœ€è¦å¤§å¹…ä¼˜åŒ–)"
    
    def _generate_recommendations(self, success_rate: float, total_times: List[float]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if success_rate < 0.8:
            recommendations.append("ğŸ’¡ æˆåŠŸç‡ä½äº80%ï¼Œéœ€è¦ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½")
        
        if total_times:
            avg_time = statistics.mean(total_times)
            if avg_time > 3.0:
                recommendations.append("ğŸ’¡ å¹³å‡å“åº”æ—¶é—´è¶…è¿‡3ç§’ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            
            max_time = max(total_times)
            if max_time > 5.0:
                recommendations.append("ğŸ’¡ æœ€å¤§å“åº”æ—¶é—´è¶…è¿‡5ç§’ï¼Œæ£€æŸ¥ç³»ç»Ÿç“¶é¢ˆ")
        
        if success_rate >= 0.8:
            recommendations.append("âœ… ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œå·²è¾¾åˆ°2-3ç§’å“åº”ç›®æ ‡")
        
        return recommendations
    
    def print_test_report(self, analysis: Dict[str, Any]):
        """æ‰“å°æµ‹è¯•æŠ¥å‘Š"""
        logger.info("ğŸ“Š 2-3ç§’å“åº”æ—¶é—´æµ‹è¯•æŠ¥å‘Š")
        logger.info("=" * 60)
        
        # æµ‹è¯•æ‘˜è¦
        summary = analysis["test_summary"]
        logger.info(f"ğŸ“‹ æµ‹è¯•æ‘˜è¦:")
        logger.info(f"   æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
        logger.info(f"   æˆåŠŸæµ‹è¯•: {summary['successful_tests']}")
        logger.info(f"   å¤±è´¥æµ‹è¯•: {summary['failed_tests']}")
        logger.info(f"   æˆåŠŸç‡: {summary['success_rate']:.1%}")
        logger.info(f"   ç›®æ ‡è¾¾æˆ: {'âœ…' if summary['target_achieved'] else 'âŒ'}")
        
        # å“åº”æ—¶é—´ç»Ÿè®¡
        times = analysis["response_times"]
        logger.info(f"â±ï¸ å“åº”æ—¶é—´ç»Ÿè®¡:")
        logger.info(f"   å¹³å‡æ€»æ—¶é—´: {times['average_total_time']:.2f}s")
        logger.info(f"   ä¸­ä½æ•°æ—¶é—´: {times['median_total_time']:.2f}s")
        logger.info(f"   æœ€çŸ­æ—¶é—´: {times['min_total_time']:.2f}s")
        logger.info(f"   æœ€é•¿æ—¶é—´: {times['max_total_time']:.2f}s")
        logger.info(f"   å¹³å‡LLMæ—¶é—´: {times['average_llm_time']:.2f}s")
        logger.info(f"   å¹³å‡TTSæ—¶é—´: {times['average_tts_time']:.2f}s")
        
        # æ€§èƒ½ç­‰çº§
        logger.info(f"ğŸ† æ€§èƒ½ç­‰çº§: {analysis['performance_grade']}")
        
        # ä¼˜åŒ–å»ºè®®
        recommendations = analysis["recommendations"]
        logger.info(f"ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for rec in recommendations:
            logger.info(f"   {rec}")
        
        logger.info("=" * 60)
    
    async def run_continuous_monitoring(self, duration_minutes: int = 5):
        """è¿è¡ŒæŒç»­ç›‘æ§"""
        logger.info(f"ğŸ”„ å¼€å§‹æŒç»­ç›‘æ§ {duration_minutes} åˆ†é’Ÿ...")
        
        start_time = time.time()
        end_time = start_time + (duration_minutes * 60)
        
        while time.time() < end_time:
            # éšæœºæµ‹è¯•
            test_inputs = [
                "Hello!", "How are you?", "What's up?", "Tell me something interesting"
            ]
            
            import random
            test_input = random.choice(test_inputs)
            
            result = await self.test_single_response(test_input)
            self.test_results.append(result)
            
            # æ¯30ç§’æµ‹è¯•ä¸€æ¬¡
            await asyncio.sleep(30)
        
        # åˆ†ææŒç»­ç›‘æ§ç»“æœ
        analysis = self.analyze_test_results()
        self.print_test_report(analysis)
        
        return analysis

async def main():
    tester = ResponseTimeTester()
    
    print("ğŸš€ 2-3ç§’å“åº”æ—¶é—´æµ‹è¯•å™¨")
    print("=" * 50)
    print("é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. ç»¼åˆæµ‹è¯• (10ä¸ªæµ‹è¯•ç”¨ä¾‹)")
    print("2. æŒç»­ç›‘æ§ (5åˆ†é’Ÿ)")
    print("3. è‡ªå®šä¹‰æµ‹è¯•")
    
    try:
        choice = input("è¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
        
        if choice == "1":
            analysis = await tester.run_comprehensive_test()
            tester.print_test_report(analysis)
            
        elif choice == "2":
            analysis = await tester.run_continuous_monitoring(5)
            
        elif choice == "3":
            test_input = input("è¯·è¾“å…¥æµ‹è¯•æ–‡æœ¬: ").strip()
            result = await tester.test_single_response(test_input)
            print(f"æµ‹è¯•ç»“æœ: {result}")
            
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œç»¼åˆæµ‹è¯•...")
            analysis = await tester.run_comprehensive_test()
            tester.print_test_report(analysis)
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ æµ‹è¯•å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
