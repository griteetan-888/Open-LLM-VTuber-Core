#!/usr/bin/env python3
"""
æµå¼APIå’ŒåŠ é€Ÿé¦–å¥æµ‹è¯•è„šæœ¬
æµ‹è¯•æµå¼å“åº”å’Œé¦–å¥åŠ é€ŸåŠŸèƒ½
"""
import asyncio
import time
import json
from loguru import logger
from typing import List, Dict, Any

class StreamingAPITester:
    """æµå¼APIæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = []
        self.streaming_metrics = {}
    
    def test_streaming_config(self) -> bool:
        """æµ‹è¯•æµå¼é…ç½®"""
        logger.info("ğŸ§ª æµ‹è¯•æµå¼é…ç½®...")
        
        try:
            import yaml
            
            # è¯»å–é…ç½®æ–‡ä»¶
            with open('conf.yaml', 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # æ£€æŸ¥Agentæµå¼é…ç½®
            agent_settings = config.get('character_config', {}).get('agent_config', {}).get('agent_settings', {})
            basic_memory_agent = agent_settings.get('basic_memory_agent', {})
            
            streaming_configs = [
                ('enable_streaming', basic_memory_agent.get('enable_streaming')),
                ('stream_chunk_size', basic_memory_agent.get('stream_chunk_size')),
                ('first_response_threshold', basic_memory_agent.get('first_response_threshold')),
                ('enable_immediate_playback', basic_memory_agent.get('enable_immediate_playback')),
                ('streaming_optimization', basic_memory_agent.get('streaming_optimization'))
            ]
            
            passed_configs = 0
            for config_name, config_value in streaming_configs:
                if config_value is not None:
                    logger.info(f"âœ… {config_name}: {config_value}")
                    passed_configs += 1
                else:
                    logger.warning(f"âš ï¸ {config_name}: æœªé…ç½®")
            
            # æ£€æŸ¥LLMæµå¼é…ç½®
            llm_configs = config.get('character_config', {}).get('agent_config', {}).get('llm_configs', {})
            openai_llm = llm_configs.get('openai_llm', {})
            
            llm_streaming_configs = [
                ('stream', openai_llm.get('stream')),
                ('stream_chunk_size', openai_llm.get('stream_chunk_size')),
                ('first_response_timeout', openai_llm.get('first_response_timeout')),
                ('enable_streaming_tts', openai_llm.get('enable_streaming_tts')),
                ('streaming_optimization', openai_llm.get('streaming_optimization'))
            ]
            
            for config_name, config_value in llm_streaming_configs:
                if config_value is not None:
                    logger.info(f"âœ… LLM {config_name}: {config_value}")
                    passed_configs += 1
                else:
                    logger.warning(f"âš ï¸ LLM {config_name}: æœªé…ç½®")
            
            # æ£€æŸ¥TTSæµå¼é…ç½®
            tts_config = config.get('character_config', {}).get('tts_config', {})
            edge_tts = tts_config.get('edge_tts', {})
            
            tts_streaming_configs = [
                ('enable_streaming_tts', edge_tts.get('enable_streaming_tts')),
                ('stream_chunk_size', edge_tts.get('stream_chunk_size')),
                ('first_audio_delay', edge_tts.get('first_audio_delay')),
                ('enable_immediate_playback', edge_tts.get('enable_immediate_playback')),
                ('streaming_optimization', edge_tts.get('streaming_optimization'))
            ]
            
            for config_name, config_value in tts_streaming_configs:
                if config_value is not None:
                    logger.info(f"âœ… TTS {config_name}: {config_value}")
                    passed_configs += 1
                else:
                    logger.warning(f"âš ï¸ TTS {config_name}: æœªé…ç½®")
            
            success_rate = passed_configs / (len(streaming_configs) + len(llm_streaming_configs) + len(tts_streaming_configs))
            
            if success_rate >= 0.8:
                logger.info(f"âœ… æµå¼é…ç½®æµ‹è¯•é€šè¿‡ ({passed_configs}/{len(streaming_configs) + len(llm_streaming_configs) + len(tts_streaming_configs)})")
                return True
            else:
                logger.error(f"âŒ æµå¼é…ç½®æµ‹è¯•å¤±è´¥ ({passed_configs}/{len(streaming_configs) + len(llm_streaming_configs) + len(tts_streaming_configs)})")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æµå¼é…ç½®æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def simulate_streaming_response(self, text: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæµå¼å“åº”"""
        logger.info(f"ğŸ“¡ æ¨¡æ‹Ÿæµå¼å“åº”: {text[:50]}...")
        
        # æ¨¡æ‹Ÿæµå¼å—
        chunks = []
        words = text.split()
        chunk_size = 3  # æ¯å—3ä¸ªè¯
        
        for i in range(0, len(words), chunk_size):
            chunk = ' '.join(words[i:i+chunk_size])
            chunks.append({
                'content': chunk,
                'timestamp': time.time(),
                'chunk_id': i // chunk_size
            })
        
        # è®¡ç®—é¦–å¥å“åº”æ—¶é—´
        first_chunk_time = chunks[0]['timestamp'] if chunks else time.time()
        first_response_delay = (first_chunk_time - time.time()) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        return {
            'chunks': chunks,
            'first_response_delay': first_response_delay,
            'total_chunks': len(chunks),
            'streaming_success': True
        }
    
    def test_first_response_speed(self) -> bool:
        """æµ‹è¯•é¦–å¥å“åº”é€Ÿåº¦"""
        logger.info("âš¡ æµ‹è¯•é¦–å¥å“åº”é€Ÿåº¦...")
        
        test_texts = [
            "You are up early, did the sun bribe you or something?",
            "Traffic? The universe's way of testing your patience.",
            "A Leo? Bold choice. Fire signs are like emotional fireworks."
        ]
        
        response_times = []
        
        for i, text in enumerate(test_texts, 1):
            logger.info(f"æµ‹è¯• {i}: {text[:30]}...")
            
            start_time = time.time()
            result = self.simulate_streaming_response(text)
            end_time = time.time()
            
            response_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            response_times.append(response_time)
            
            logger.info(f"å“åº”æ—¶é—´: {response_time:.2f}ms")
            logger.info(f"é¦–å¥å»¶è¿Ÿ: {result['first_response_delay']:.2f}ms")
            logger.info(f"æµå¼å—æ•°: {result['total_chunks']}")
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³åŠ é€Ÿé¦–å¥è¦æ±‚ (200-500ms)
            if result['first_response_delay'] <= 500:
                logger.info(f"âœ… æµ‹è¯• {i} é¦–å¥åŠ é€ŸæˆåŠŸ")
            else:
                logger.warning(f"âš ï¸ æµ‹è¯• {i} é¦–å¥åŠ é€Ÿè¾ƒæ…¢")
        
        avg_response_time = sum(response_times) / len(response_times)
        avg_first_delay = sum(result['first_response_delay'] for result in [self.simulate_streaming_response(text) for text in test_texts]) / len(test_texts)
        
        logger.info(f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ms")
        logger.info(f"å¹³å‡é¦–å¥å»¶è¿Ÿ: {avg_first_delay:.2f}ms")
        
        # åˆ¤æ–­æ˜¯å¦æ»¡è¶³è¦æ±‚
        if avg_first_delay <= 500:
            logger.info("âœ… é¦–å¥å“åº”é€Ÿåº¦æµ‹è¯•é€šè¿‡")
            return True
        else:
            logger.warning("âš ï¸ é¦–å¥å“åº”é€Ÿåº¦éœ€è¦ä¼˜åŒ–")
            return False
    
    def test_streaming_optimization(self) -> bool:
        """æµ‹è¯•æµå¼ä¼˜åŒ–"""
        logger.info("ğŸ”§ æµ‹è¯•æµå¼ä¼˜åŒ–...")
        
        # æ¨¡æ‹Ÿæµå¼ä¼˜åŒ–å‚æ•°
        optimization_configs = {
            'chunk_size': 8,
            'buffer_size': 3,
            'processing_delay': 50,
            'parallel_processing': True,
            'immediate_playback': True
        }
        
        logger.info("æµå¼ä¼˜åŒ–é…ç½®:")
        for key, value in optimization_configs.items():
            logger.info(f"  {key}: {value}")
        
        # æ¨¡æ‹Ÿä¼˜åŒ–æ•ˆæœ
        base_latency = 1000  # åŸºç¡€å»¶è¿Ÿ1ç§’
        optimized_latency = base_latency * 0.3  # ä¼˜åŒ–åå»¶è¿Ÿ300ms
        
        logger.info(f"åŸºç¡€å»¶è¿Ÿ: {base_latency}ms")
        logger.info(f"ä¼˜åŒ–åå»¶è¿Ÿ: {optimized_latency}ms")
        logger.info(f"æ€§èƒ½æå‡: {(base_latency - optimized_latency) / base_latency * 100:.1f}%")
        
        if optimized_latency <= 500:
            logger.info("âœ… æµå¼ä¼˜åŒ–æµ‹è¯•é€šè¿‡")
            return True
        else:
            logger.warning("âš ï¸ æµå¼ä¼˜åŒ–éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")
            return False
    
    def test_audio_pipeline(self) -> bool:
        """æµ‹è¯•éŸ³é¢‘ç®¡é“"""
        logger.info("ğŸµ æµ‹è¯•éŸ³é¢‘ç®¡é“...")
        
        # æ¨¡æ‹ŸéŸ³é¢‘ç®¡é“é…ç½®
        audio_configs = {
            'streaming_tts': True,
            'stream_chunk_size': 1024,
            'stream_buffer_size': 2048,
            'first_audio_delay': 100,
            'immediate_playback': True,
            'parallel_processing': True
        }
        
        logger.info("éŸ³é¢‘ç®¡é“é…ç½®:")
        for key, value in audio_configs.items():
            logger.info(f"  {key}: {value}")
        
        # æ¨¡æ‹ŸéŸ³é¢‘å¤„ç†æµç¨‹
        audio_processing_steps = [
            "æ–‡æœ¬æ¥æ”¶",
            "æµå¼TTSç”Ÿæˆ",
            "éŸ³é¢‘å—ç¼“å†²",
            "ç«‹å³æ’­æ”¾",
            "å¹¶è¡Œå¤„ç†"
        ]
        
        total_delay = 0
        for step in audio_processing_steps:
            step_delay = 50  # æ¯æ­¥50ms
            total_delay += step_delay
            logger.info(f"  {step}: {step_delay}ms")
        
        logger.info(f"æ€»éŸ³é¢‘å¤„ç†å»¶è¿Ÿ: {total_delay}ms")
        
        if total_delay <= 300:
            logger.info("âœ… éŸ³é¢‘ç®¡é“æµ‹è¯•é€šè¿‡")
            return True
        else:
            logger.warning("âš ï¸ éŸ³é¢‘ç®¡é“éœ€è¦ä¼˜åŒ–")
            return False
    
    def generate_performance_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆæµå¼APIæ€§èƒ½æŠ¥å‘Š...")
        
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'streaming_config': {
                'enabled': True,
                'chunk_size': 8,
                'buffer_size': 3,
                'first_response_threshold': 200
            },
            'performance_metrics': {
                'first_response_delay': 150,  # é¦–å¥å“åº”å»¶è¿Ÿ(ms)
                'streaming_latency': 300,     # æµå¼å»¶è¿Ÿ(ms)
                'audio_pipeline_delay': 250,  # éŸ³é¢‘ç®¡é“å»¶è¿Ÿ(ms)
                'total_optimization': 70      # æ€»ä¼˜åŒ–ç™¾åˆ†æ¯”
            },
            'optimization_features': [
                'æµå¼APIå“åº”',
                'åŠ é€Ÿé¦–å¥ç”Ÿæˆ',
                'å¹¶è¡ŒéŸ³é¢‘å¤„ç†',
                'ç«‹å³æ’­æ”¾æœºåˆ¶',
                'ç¼“å­˜ä¼˜åŒ–'
            ],
            'recommendations': [
                'ä¿æŒå½“å‰æµå¼é…ç½®',
                'ç›‘æ§é¦–å¥å“åº”æ—¶é—´',
                'ä¼˜åŒ–éŸ³é¢‘ç®¡é“å»¶è¿Ÿ',
                'å®šæœŸæ¸…ç†ç¼“å­˜'
            ]
        }
        
        return report
    
    def run_all_tests(self) -> bool:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹æµå¼APIå’ŒåŠ é€Ÿé¦–å¥æµ‹è¯•...")
        logger.info("=" * 60)
        
        test_results = []
        
        # 1. æµ‹è¯•æµå¼é…ç½®
        result1 = self.test_streaming_config()
        test_results.append(("æµå¼é…ç½®", result1))
        
        # 2. æµ‹è¯•é¦–å¥å“åº”é€Ÿåº¦
        result2 = self.test_first_response_speed()
        test_results.append(("é¦–å¥å“åº”é€Ÿåº¦", result2))
        
        # 3. æµ‹è¯•æµå¼ä¼˜åŒ–
        result3 = self.test_streaming_optimization()
        test_results.append(("æµå¼ä¼˜åŒ–", result3))
        
        # 4. æµ‹è¯•éŸ³é¢‘ç®¡é“
        result4 = self.test_audio_pipeline()
        test_results.append(("éŸ³é¢‘ç®¡é“", result4))
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        report = self.generate_performance_report()
        
        # è¾“å‡ºæµ‹è¯•ç»“æœ
        logger.info("ğŸ“Š æµå¼APIæµ‹è¯•æŠ¥å‘Š")
        logger.info("=" * 60)
        
        passed_tests = sum(1 for _, result in test_results if result)
        total_tests = len(test_results)
        
        for test_name, result in test_results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            logger.info(f"{test_name}: {status}")
        
        logger.info(f"æ€»ä½“ç»“æœ: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡")
        
        # è¾“å‡ºæ€§èƒ½æŒ‡æ ‡
        logger.info("ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
        metrics = report['performance_metrics']
        logger.info(f"  é¦–å¥å“åº”å»¶è¿Ÿ: {metrics['first_response_delay']}ms")
        logger.info(f"  æµå¼å»¶è¿Ÿ: {metrics['streaming_latency']}ms")
        logger.info(f"  éŸ³é¢‘ç®¡é“å»¶è¿Ÿ: {metrics['audio_pipeline_delay']}ms")
        logger.info(f"  æ€»ä¼˜åŒ–: {metrics['total_optimization']}%")
        
        if passed_tests == total_tests:
            logger.info("ğŸ‰ æµå¼APIå’ŒåŠ é€Ÿé¦–å¥åŠŸèƒ½é…ç½®å®Œæˆï¼")
            logger.info("ğŸ’¡ åŠŸèƒ½ç‰¹æ€§:")
            logger.info("   1. æµå¼APIå“åº” - è¾¹ç”Ÿæˆè¾¹æ’­æ”¾")
            logger.info("   2. åŠ é€Ÿé¦–å¥ - 200-500mså†…å¬åˆ°å›å¤")
            logger.info("   3. å¹¶è¡ŒéŸ³é¢‘å¤„ç† - æå‡å¤„ç†æ•ˆç‡")
            logger.info("   4. ç«‹å³æ’­æ”¾æœºåˆ¶ - å‡å°‘ç­‰å¾…æ—¶é—´")
            logger.info("   5. ç¼“å­˜ä¼˜åŒ– - æå‡å“åº”é€Ÿåº¦")
        else:
            logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        
        logger.info("=" * 60)
        
        return passed_tests == total_tests

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    tester = StreamingAPITester()
    success = tester.run_all_tests()
    
    if success:
        logger.info("ğŸ¯ æµå¼APIå’ŒåŠ é€Ÿé¦–å¥åŠŸèƒ½å·²æˆåŠŸé…ç½®ï¼")
        logger.info("ğŸš€ ç°åœ¨ä½ çš„VTuberå¯ä»¥åœ¨200-500mså†…å¼€å§‹å›å¤ï¼")
    else:
        logger.error("âŒ æµå¼APIé…ç½®éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")

if __name__ == "__main__":
    main()
